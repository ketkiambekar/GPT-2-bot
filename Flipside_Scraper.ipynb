{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flipside_Scraper.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPI9LveRprQCxJbrD8PmB6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ketkiambekar/ResiBot/blob/master/Flipside_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noZHToaOX3T9"
      },
      "source": [
        "##Program to scrap the home page of Flipside.io\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnub-62kIfCK"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "\n",
        "homepage = requests.get(\"https://www.theflipside.io/archives\").text\n",
        "\n",
        "soup = BeautifulSoup(homepage,'lxml')\n",
        "#print(soup.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhoH5MbkYAg2"
      },
      "source": [
        "Get Hrefs of all links on the Archives Page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNXvC4mUMGF5",
        "outputId": "74067dff-b7fb-4eb0-b891-cde70a4070b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\n",
        "\n",
        "links=[]\n",
        "links_with_text = [a['href'] for a in soup.find_all('a', href=True) if a.text]\n",
        "print(links_with_text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/latest-issue', '/archives', '/about-us', '/our-supporters', '/faq', '/latest-issue', '/archives', '/about-us', '/donate', '/faq', '/archives/supreme-court-on-religious-schools', '/archives/russia-taliban-bounties', '/archives/scotus-abortion-ruling', '/archives/dc-statehood', '/archives/general-election-update-2', '/archives/michael-flynn-3', '/archives/immigration-restrictions-2', '/archives/statues', '/archives/juneteenth', '/archives/supreme-court-rules-on-daca', '/archives/boltons-book-2', '/archives/trump-signs-executive-order', '/archives/supreme-court-rules-on-lgbtq-rights', '/archives/reopening-and-covid', '/archives/media-hollywood-and-the-protests', '/archives/remembering-confederate-generals', '/archives/troops-to-be-withdrawn-from-germany', '/archives/jobs-report-2', '/archives/defunding-the-police', '/archives/hong-kong-2', '/archives/steve-king-primary-elections', '/archives/trump-and-the-protests', '/archives/police-reform', '/archives/police-protests', '/archives/trump-vs-twitter', '/archives/hong-kong', '/archives/trump-tweets', '/archives/campaign-update', '/archives/states-reopening-2', '/archives/state-department-ig-fired', '/archives/us-china-relations', '/archives/heroes-act', '/archives/wisconsin', '/archives/obamagate', '/archives/elon-musk', '/archives/ahmaud-arbery', '/archives/michael-flynn-2', '/archives/title-ix', '/archives/contraception-mandate', '/archives/lockdown-lawsuits', '/archives/general-election-update', '/archives/michael-flynn', '/archives/reopening-meat-plants', '/archives/amash-considers-presidential-run', '/archives/global-responses-to-coronavirus', '/archives/bidens-assault-allegations-and-vp-choice', '/archives/states-reopening', '/archives/state-bailouts', '/archives/earth-day', '/archives/immigration-suspended', '/archives/scotus-requires-unanimous-juries', '/archives/adjourning-congress', '/archives/coronavirus-bailouts', '/archives/who-funding', '/archives/joe-biden-2021', '/archives/reopening-the-economy', '/archives/race-and-coronavirus', '/archives/who-under-fire', '/archives/sanders-ends-campaign', '/archives/wisconsin-election', '/archives/oil-price-war', '/archives/captain-crozier', '/archives/china-and-coronavirus', '/archives/election-update', '/archives/defense-production-act', '/archives/venezuela', '/archives/life-after-coronavirus', '/archives/q-a-with-the-duff-phelps-institute', '/archives/coronavirus-relief-bill', '/archives/2020-election', '/archives/senators-sell-stock', '/archives/senate-coronavirus-bill', '/archives/us-and-china', '/archives/checks-in-the-mail', '/archives/coronavirus-and-the-economy', '/archives/coronavirus-and-the-primaries', '/archives/coronavirus-aid-package', '/archives/biden-vs-bernie-2', '/archives/coronavirus-ruins-everything', '/archives/coronavirus-2', '/archives/afghanistan-icc', '/archives/state-of-the-economy', '/archives/june-medical', '/archives/biden-vs-bernie', '/archives/super-tuesday', '/archives/us-taliban-deal', '/archives/south-carolina-primary', '/archives/weinstein-convicted', '/archives/coronavirus', '/archives/democratic-debate-6', '/archives/richard-grenell-appointed-acting-dni', '/archives/nevada-caucus', '/archives/barr-and-stone', '/archives/democratic-debate-5', '/archives/clemency', '/archives/bloombergs-candidacy', '/archives/roger-stones-sentence', '/archives/new-hampshire-primary', '/archives/white-house-budget-proposal', '/archives/democratic-debate-4', '/archives/senate-acquits-trump', '/archives/state-of-the-union-2', '/archives/iowa-caucus-results', '/archives/iowa-caucus-results-delayed', '/archives/iowa-caucuses-preview', '/archives/brexit', '/archives/immigration-restrictions', '/archives/mideast-peace-plan', '/archives/boltons-book', '/archives/march-for-life', '/archives/davos', '/archives/impeachment-trial-begins', '/archives/nyt-endorsements', '/archives/lev-parnas', '/archives/impeachment-3', '/archives/democratic-debate-3', '/archives/cory-booker-drops-out', '/archives/jobs-report', '/archives/bernie-surges', '/archives/iran-de-escalation', '/archives/impeachment-update-4', '/archives/possible-troop-withdrawal', '/archives/soleimani-killed', '/archives/democratic-debate-2', '/archives/house-votes-to-impeach', '/archives/china-trade-deal', '/archives/usmca-2', '/archives/uk-election', '/archives/anti-semitism-eo', '/archives/biden-fights-back', '/archives/inspector-generals-report', '/archives/afghanistan-papers', '/archives/impeachment-2', '/archives/food-stamps', '/archives/nato-summit', '/archives/kamala-harris-drops-out', '/archives/tariffs', '/archives/trumps-tax-returns', '/archives/hong-kong-elections', '/archives/clemency-for-three-military-officers', '/archives/impeachment-hearings-continue', '/archives/democratic-debate', '/archives/israeli-settlements', '/archives/xinjiang-abuses-exposed', '/archives/yovanovitch-testifies', '/archives/pete-buttigieg-rising', '/archives/impeachment-hearings-begin', '/archives/supreme-court-hears-daca-case', '/archives/bloomberg-considering-presidential-run', '/archives/kamala-harriss-school-plan', '/archives/election-results', '/archives/swing-state-polls', '/archives/california-wildfires', '/archives/warren-releases-healthcare-plan', '/archives/house-votes-for-impeachment-inquiry', '/latest-issue', '/archives', '/about-us', '/media', '/our-supporters', '/faq', '/terms', 'https://www.functionlabs.com', '/donate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOubwwLtmePo"
      },
      "source": [
        "Get Html markup of each article on Archives page and extract only leftist/rightist paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsaj8lrqIPE5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "content=[]\n",
        "for link in links_with_text:\n",
        "  if link.startswith('/archives/'):\n",
        "    page = requests.get(\"https://www.theflipside.io\"+link).text\n",
        "    soup1 = BeautifulSoup(page,'lxml')\n",
        "    content=get_left(soup1,content)\n",
        "    #content=get_right(soup1,content)\n",
        "\n",
        "df2 = pd.DataFrame(content, columns = ['Title', 'Left_Content']) \n",
        "df2.head(50)\n",
        "\n",
        "#df1 = pd.DataFrame(content, columns = ['Title', 'Right_Content']) \n",
        "#df1.head(50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSy0TidClC2P"
      },
      "source": [
        "#Function to extract rightist content\n",
        "def get_right(soup1,df):\n",
        "\n",
        "  #get title \n",
        "  title = soup1.find('h1', class_=\"heading-17\").text\n",
        "  title = title.replace('â',\"'\").replace('â¦','...').replace('â ','—').replace('â','').replace('â','').replace('â',\"'\").replace('â','')\n",
        "  #print(title)\n",
        "\n",
        "  left = soup1.find('div', class_=\"column-60 w-clearfix w-col w-col-6 w-col-small-6 w-col-tiny-tiny-stack\")\n",
        "  if not left.text.strip().lower().startswith('from the right'):\n",
        "    left = soup1.find('div', class_=\"column-61 w-clearfix w-col w-col-6 w-col-small-6 w-col-tiny-tiny-stack\")\n",
        "\n",
        "  #get writers\n",
        "  writers = soup1.find_all('strong')\n",
        "  pointer=len('From the right')   #For extracting substring\n",
        "\n",
        "  for name in writers:\n",
        "    index=-1\n",
        "    index2=-1\n",
        "    index3=-1\n",
        "    name_lenght=0\n",
        "    content=''\n",
        "    try:\n",
        "      name_lenght= len(name.text)\n",
        "      index=name.text.index(',')\n",
        "      index2=name.text.index(':')\n",
        "    except:\n",
        "      #print(index2)\n",
        "      pass\n",
        "    if index >=0 and index2==-1:\n",
        "      name_index=-1\n",
        "      try:\n",
        "        #print(name, left.text)\n",
        "        name_index=left.text.index(name.text)\n",
        "        #print(name_index)\n",
        "      except:\n",
        "        #print('exp',name_index)\n",
        "        pass\n",
        "      if name_index>=0:\n",
        "        #print(type(name_index), type(name_lenght))\n",
        "        content = (left.text)[pointer: (name_index + name_lenght)]\n",
        "        try:\n",
        "          pointer = left.text.index(name.text) + name_lenght\n",
        "        except:\n",
        "          pass\n",
        "        content = content.replace('â',\"'\").replace('â¦','...').replace('â ','—').replace('â','').replace('â','').replace('â',\"'\").replace('â','')\n",
        "    \n",
        "      #print(content)\n",
        "      if len(content)>0 and len(title)>0:\n",
        "        df.append((title, content))\n",
        "    \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pSaHg5DxRrn"
      },
      "source": [
        "#Function to extract Leftist content\n",
        "def get_left(soup1,df):\n",
        "  #get title \n",
        "  \n",
        "  title = soup1.find('h1', class_=\"heading-17\").text\n",
        "  title = title.replace('â',\"'\").replace('â¦','...').replace('â ','—').replace('â','').replace('â','').replace('â',\"'\").replace('â','')\n",
        "  #print(title)\n",
        "\n",
        "  left = soup1.find('div', class_=\"column-60 w-clearfix w-col w-col-6 w-col-small-6 w-col-tiny-tiny-stack\")\n",
        "  if not left.text.strip().lower().startswith('from the left'):\n",
        "    left = soup1.find('div', class_=\"column-61 w-clearfix w-col w-col-6 w-col-small-6 w-col-tiny-tiny-stack\")\n",
        "\n",
        "  #remove text \"from the right\" from the beginning\n",
        "\n",
        "\n",
        "  writers = soup1.find_all('strong')\n",
        " \n",
        "  #print(writers)\n",
        "\n",
        "  pointer=len('From the left')\n",
        "\n",
        "  for name in writers:\n",
        "    index=-1\n",
        "    index2=-1\n",
        "    index3=-1\n",
        "    name_lenght=0\n",
        "    content=''\n",
        "    try:\n",
        "      name_lenght= len(name.text)\n",
        "      index=name.text.index(',')\n",
        "      index2=name.text.index(':')\n",
        "    except:\n",
        "      #print(index2)\n",
        "      pass\n",
        "    if index >=0 and index2==-1:\n",
        "      name_index=-1\n",
        "      try:\n",
        "        #print(name, left.text)\n",
        "        name_index=left.text.index(name.text)\n",
        "        #print(name_index)\n",
        "      except:\n",
        "        pass\n",
        "      if name_index>=0:\n",
        "        #print(type(name_index), type(name_lenght))\n",
        "        content = (left.text)[pointer: (name_index + name_lenght)]\n",
        "        try:\n",
        "          pointer = left.text.index(name.text) + name_lenght\n",
        "        except:\n",
        "          pass\n",
        "        content = content.replace('â',\"'\").replace('â¦','...').replace('â ','—').replace('â','').replace('â','').replace('â',\"'\").replace('â','')\n",
        "    \n",
        "      #print(content)\n",
        "      if len(content)>0 and len(title)>0:\n",
        "        df.append((title, content))\n",
        "    \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zxU5EZMKlTU"
      },
      "source": [
        "def get_left_old(soup1,df):\n",
        "  #get title \n",
        "  title = soup1.find('h1', class_=\"heading-17\").text\n",
        "  #print(title)\n",
        "\n",
        "  left = soup1.find('div', class_=\"column-60 w-clearfix w-col w-col-6 w-col-small-6 w-col-tiny-tiny-stack\").text\n",
        "  if not left.strip().lower().startswith('from the left'):\n",
        "    left = soup1.find('div', class_=\"column-61 w-clearfix w-col w-col-6 w-col-small-6 w-col-tiny-tiny-stack\").text\n",
        "\n",
        "\n",
        "  #left = left.replace('â',\"'\").replace('â¦','...').replace('â ','—').replace('â','').replace('â','').replace('â',\"'\").replace('â','')\n",
        "  #print(left)\n",
        "\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Tq1rTjom2Tc"
      },
      "source": [
        "Save the Data Frames into CSV files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx1LUmDVhjcD"
      },
      "source": [
        "df2.to_csv('Flipside_Left.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDgdnkh0YYbf"
      },
      "source": [
        "df1.to_csv('Flipside_Right.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
