{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGUrtW-UxELY",
        "colab_type": "text"
      },
      "source": [
        "#GPT-2 Model training for ResiBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDKO-IoKxOPW",
        "colab_type": "text"
      },
      "source": [
        "Resi Bot is a text generator bot that was a part of Resilience2032 project that took place in September 2020. This project was a thought experiment on how our world will look like in the year 2032. It explored a variety of issues related to racism, sexism, climate, etc and sought to answer what steps we could take to mitigate these issues. It was anticipated that AI bots would be prolific around that time, and the ResiBot was developed to play the role of the contemporary AI. The bot is trained on a corpus curated by the writers' team of Resilience2032 to generate text that produced the effect of being in the year 2032. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3slfD6dkwm_t",
        "colab_type": "text"
      },
      "source": [
        "This note book shows how to train a GPT-2 model and generate a test paragraph of text based on our training Corpus data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cv_Cf-aeE_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell mounts the Google Drive. Upload the text file containing the training text, to your google drive. \n",
        "# This code assumes that the file is on the root of your google drive, but if you have it in a sub folder, then you need to modify the path in line 7.\n",
        "# Line 9 displays all the file present in the folder path provided in line 7\n",
        "# Run the cell, click on the link that appears, login and enter the code in the box to mount the drive. \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/My Drive')\n",
        "\n",
        "%ls\n",
        "\n",
        "%pwd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLXOI8y3wW5c",
        "colab_type": "text"
      },
      "source": [
        "Lod all the libraries, including Tensor flow and GPT-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkre8FUPQf-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8ef6fbd7-2e4b-468c-99a7-47bc71487b5a"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdfBzB-iu2Dv",
        "colab_type": "text"
      },
      "source": [
        "Check the Details of GPU allocated to us by Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OGiUg-vSZRX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1a26c361-e903-4a11-91dc-1a5c88e98b68"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep  8 10:52:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLB4Wy3evh2L",
        "colab_type": "text"
      },
      "source": [
        "Download the Gpt-2 model. For our project we are using the smallest model having 124 Million parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lumqIF1g655",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "95a1edde-42dd-4120-ac4b-9a268ec59ae9"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 412Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 107Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 395Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:02, 174Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 281Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 155Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 168Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_cV59F9XIBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.mount_gdrive()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSsax8ENv2Qm",
        "colab_type": "text"
      },
      "source": [
        "Enter the name of the Training Corpus File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMP0FkfAXyi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In this cell, you need to supply the name of the text file to be used for training. Just change the red colored text per your filename. \n",
        "file_name=\"f_corpus.txt\"\n",
        "gpt2.copy_file_from_gdrive(file_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oICzuhlv9VX",
        "colab_type": "text"
      },
      "source": [
        "Start a session to train our GPT-2 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMI7zw44gLq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6f85168-c7a5-4fbf-fdcc-30d0a20008b9"
      },
      "source": [
        "#Running this cell will begin the training of the model. \n",
        "#It may take a while, sometimes upto 30 mins. \n",
        "#The generated text will be displayed in the output \n",
        "\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='AIR',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 406448 tokens\n",
            "Training...\n",
            "[10 | 29.37] loss=3.54 avg=3.54\n",
            "[20 | 51.69] loss=3.45 avg=3.50\n",
            "[30 | 74.41] loss=3.26 avg=3.42\n",
            "[40 | 97.77] loss=3.43 avg=3.42\n",
            "[50 | 121.11] loss=3.40 avg=3.42\n",
            "[60 | 144.09] loss=3.10 avg=3.36\n",
            "[70 | 167.14] loss=3.16 avg=3.33\n",
            "[80 | 190.38] loss=3.21 avg=3.32\n",
            "[90 | 213.55] loss=3.44 avg=3.33\n",
            "[100 | 236.69] loss=2.87 avg=3.28\n",
            "[110 | 259.87] loss=3.01 avg=3.26\n",
            "[120 | 283.11] loss=2.77 avg=3.21\n",
            "[130 | 306.37] loss=2.95 avg=3.19\n",
            "[140 | 329.61] loss=2.85 avg=3.17\n",
            "[150 | 352.84] loss=3.01 avg=3.15\n",
            "[160 | 376.05] loss=3.11 avg=3.15\n",
            "[170 | 399.24] loss=2.55 avg=3.11\n",
            "[180 | 422.41] loss=3.25 avg=3.12\n",
            "[190 | 445.57] loss=2.76 avg=3.10\n",
            "[200 | 468.73] loss=2.52 avg=3.07\n",
            "======== SAMPLE 1 ========\n",
            " gas people.\n",
            "\n",
            "But how to get people to stop buying products that are harmful and toward embracing an open alternative marketplace where health care is made non-discriminatory without barriers or mandates? The answer is through engaging with employers, insurers, consumers and technology companies to develop and implement voluntary standards for the production, distribution and use of ethically harvested foodstuffs.\n",
            "\n",
            "The principles defined by these voluntary standards must be aligned with the values and ethical codes of our industrial farming communities. Ethical sourcing, responsible sourcing and agroecological conservation are foundational principles at the heart of sustainability and are essential if sustainable farming is to truly become the new normal.\n",
            "\n",
            "The Ethical Harvesting Practice (ESTP): The third and final pillar of sustainable farming is agroecological conservation and management.\n",
            "\n",
            "It is an invitation-only endeavor that combines farmer-to-farmer communications with farmer-to-environmental networks on social media.\n",
            "\n",
            "The ETHICAI firm brings together agroecologists from around the world to share their knowledge, create custom agroecological conservation management software, and conduct ecosystem mobilization and resilience research at their community-run agroecological consulting firm, Afroforestalk.\n",
            "\n",
            "\n",
            "The Afroforestalk partnership focuses on sustainable farming practices and partnerships in developing countries to support sustainable farming communities on social media and through traditional agroecological methods. Each Afroforestalk employee is assigned a staff of farmers or producers and assigned to produce the crop during the working week and are responsible for its care.\n",
            "\n",
            "Through their social media platforms, they share their farmer-to-farmer information, discuss agroecological issues, and share their experience building agroecological conservation tools including agroecological grids and network. Afroforestalk programs are driven by the idea of sustainability across diverse farming interests with a focus on the need for an ecologically sound farming workforce for large-scale agroecological farming.\n",
            "\n",
            "Each Afroforestalk employee creates an agroecological management group within Afroforestalk and then contributes to the agroecological conservation project of Afroforestalk.\n",
            "\n",
            "Working remotely from home and on-call from Afroforestalk's farm, working on project management days, planning work nights and other work-related opportunities, Afroforestalk participants find their sustainable livelihoods in the farming communities.\n",
            "\n",
            "The Afroforestalk collective raises and engages consumers at all walks of life through agroecological activism, philanthropy and farming stewardship through agroecology workshops and farmer demonstrations and through education in agroforestry.\n",
            "\n",
            "Through Afroforestalk activities, the collective engages and engages with farmers in food, environmental and farmer issues at farmer-to- farmer level. Afroforestalk participants learn more and improve on each other's methods in agroecology at workshops, networking to benefit farmers from all walks of life.\n",
            "\n",
            "These efforts help feed the agroecological movement by increasing agroforestry experience and help farmers increase their sustainability goals through farming sustainability strategies.\n",
            "\n",
            "Working from home, students who are engaged in agroecological conservation work, farm groups, farmer demonstrations and farming stewardship events in Afroforestalk districts and farms in rural and urban Zimbabwe.\n",
            "\n",
            "Through farmers planting seeds, encouraging farmers to consider planting in open fields and planting on grazing lands, the Afroforestalk participants can further support agroecology in their community.\n",
            "\n",
            "The use of agroecological methods like biocrafting and cropland farming reduces yields by encouraging local soil biocultures and regenerating soil from desertification and permafrost melt. And these methods help farmers grow crops that sustainably manage precipitation levels, manage pests and diseases, reduce water use and minimize water scarcity.\n",
            "\n",
            "\n",
            "For more information about Afroforestalk participation opportunities please contact Adebonso Ortiz, Adebrián Gómez, Gerardo A. Galland, Andrés M. Fusco, Gáboro, and José Gómez at adebruenots@afroforestalk.org.\n",
            "\n",
            "Through Afroforestalk partnerships, community-based agroecology workshops and farming stewardship events, the Afroforestalk participants continue to improve, strengthen and grow on our partnerships.\n",
            "\n",
            "This is an exciting time to be a participant in sustainable agriculture initiatives. The emergence of sustainable farmers and farmers unions in the last few years, as a means of mobilizing the agrarian forces of the land and the rural economy has given a new urgency to agroecology efforts.\n",
            "\n",
            "The agroecologist and the agroecologist union are the two main forces supporting agrarian democracy and agrarian land reform.\n",
            "\n",
            "As agrarian agrarians, we also need to think and change how farming is practiced and how agrarian movements and agrarian workers organize and work for agrarian causes.\n",
            "\n",
            "We do this with\n",
            "\n",
            "[210 | 503.98] loss=2.60 avg=3.04\n",
            "[220 | 527.22] loss=2.65 avg=3.02\n",
            "[230 | 550.40] loss=2.22 avg=2.99\n",
            "[240 | 573.55] loss=2.34 avg=2.96\n",
            "[250 | 596.68] loss=2.28 avg=2.92\n",
            "[260 | 619.86] loss=2.06 avg=2.89\n",
            "[270 | 643.07] loss=1.81 avg=2.84\n",
            "[280 | 666.23] loss=2.41 avg=2.82\n",
            "[290 | 689.37] loss=1.99 avg=2.79\n",
            "[300 | 712.49] loss=2.16 avg=2.77\n",
            "[310 | 735.62] loss=1.51 avg=2.72\n",
            "[320 | 758.76] loss=2.26 avg=2.70\n",
            "[330 | 781.89] loss=1.49 avg=2.66\n",
            "[340 | 805.04] loss=2.03 avg=2.64\n",
            "[350 | 828.18] loss=1.92 avg=2.61\n",
            "[360 | 851.33] loss=1.84 avg=2.59\n",
            "[370 | 874.49] loss=1.24 avg=2.54\n",
            "[380 | 897.64] loss=1.96 avg=2.53\n",
            "[390 | 920.80] loss=2.35 avg=2.52\n",
            "[400 | 943.97] loss=1.53 avg=2.49\n",
            "======== SAMPLE 1 ========\n",
            " the global warming scare. The White House says the IPCC report, which has not yet been published, is “as accurate as anybody we know today. It is “as accurate as anybody could have imagined. ” But the president’s assertion that the report is “as accurate as anyone” is demonstrably false.\n",
            "\n",
            "Even then, the United Nations climate chief has repeatedly said the United Nations does not know the true level of greenhouse gas (GHG) emissions that are contributing to the current heatwaves and droughts in developing nations.\n",
            "\n",
            "UNFCCC president Tom Friedman dismissed this as a “sad news” because “it’s not true. Climate change is happening. We are in the middle of it.\n",
            "\n",
            "” But the reality is, the climate is changing much faster than climate scientists forecast two decades ago. The globe’s population continues to grow, while global temperature rises. And the global population as a whole grows. So even ten years from now, if global GHGs continue to rise, the chance of another rise of 8. 8°C is about 40%.\n",
            "\n",
            "Even if the UNDP scientists manage to lower the true annual growth line from 15.\n",
            "\n",
            "8°C to 6°F (2°C) by 2030—a pretty radical proposition given that many developing nations will continue to grow—it still leaves some unanswered questions. For instance, how many more people will die from climate change before we see a rise of asymptomatic people getting older? How much more severe the drought and wildfires that engulfed much of the West may spread to East Africa? And how many more people will die during the drought in the form of wildfires in the Southwest and wildfires in the south of Mexico? And how many more cities will experience the drought and wildfires that killed more people?And how many more hurricanes will make it to the U. S. mainland before flooding begins in some communities?And how many more years will it take for global temperatures to rise before people in developing nations see their climate as stable and healthy? And how many more years will it take before people in poor and landlocked nations see their climate as dangerously unstable?Those are just a handful of the challenges facing post-emergent humanity.\n",
            "\n",
            "Many of us may not be aware of the other way around: nanotechnology. The UNDP scientists successfully built protective products that protect against nanomaterials made from gold nanoparticles, an extremely stable, oxygen-depleting compound found in water.\n",
            "\n",
            "These products can be made in a variety of ways—some with laser technology, others with polymer technology. Some products are manufactured by soaking beads in polystyrene (PDT), which is known to block the enzymes that are needed to make carbon nanotubes. Other materials, like carbon nanotube glass, use hydrophobic properties to bond to walls, and tetraalkyl ether, which has a silica structure.\n",
            "\n",
            "These materials are among the many advances that have made nanotech possible. But even within the nanotech community, there are some small issues that emerge that frustrate many of the existing approaches.\n",
            "\n",
            "Some people within the industry see nanotech as an unnecessary step that only benefits the few leading the way in the quest to build more of them. Others see nanotech as an important part of the fight against disease and hope others may take notice.\n",
            "\n",
            "In fact, many within the technology industry are increasingly attracted to the idea of creating nanotech, believing they will one day gain greater control over their product development. Those seeking to carve out a larger role within the industry hope that this fervor will inspire other leaders to follow suit and create niches for themselves.\n",
            "\n",
            "But to reach this desire, creativity and innovation must come first, and be truly interdependent. For many of us doing our part, that is becoming increasingly difficult. In 2013, for example, I started a nonprofit called Make Noise to fight global warming.\n",
            "\n",
            "This is an organization committed to the importance of creating cultural change through listening to people, listening community, listening way back.  Some nonprofits are trying to do this differently.\n",
            "\n",
            "For instance, the Wildlife Fund of the World is setting up \"smart cities,\" a city planning practice that encourages the creation of protected areas for protected species. The nonprofit has set up ad campaigns targeting municipalities and the government, and is targeting 10,000 animals a day from hearing towers over car horns and in zebra-print kangaroos.\n",
            "\n",
            "And the Humane Society of the United States is also working to end cruelty to animals around the world. These three organizations are among hundreds of nonprofits and think tanks working to change the world through creating natural cities.\n",
            "\n",
            "But the road to creating a healthy city—one with a diverse mix of places and activities—can be incredibly time-consuming, and many cities are struggling to get their buildings and structures ready for occupancy.\n",
            "\n",
            "So what are our strategies for creating healthy, inclusive, and\n",
            "\n",
            "[410 | 977.84] loss=1.49 avg=2.46\n",
            "[420 | 1001.00] loss=2.29 avg=2.46\n",
            "[430 | 1024.19] loss=1.73 avg=2.44\n",
            "[440 | 1047.42] loss=1.42 avg=2.41\n",
            "[450 | 1070.67] loss=1.80 avg=2.39\n",
            "[460 | 1093.88] loss=1.29 avg=2.36\n",
            "[470 | 1117.08] loss=1.89 avg=2.35\n",
            "[480 | 1140.25] loss=1.61 avg=2.33\n",
            "[490 | 1163.41] loss=0.85 avg=2.29\n",
            "[500 | 1186.56] loss=1.59 avg=2.27\n",
            "Saving checkpoint/AIR/model-500\n",
            "[510 | 1212.25] loss=1.00 avg=2.24\n",
            "[520 | 1235.54] loss=1.12 avg=2.21\n",
            "[530 | 1258.72] loss=1.54 avg=2.20\n",
            "[540 | 1281.89] loss=1.00 avg=2.17\n",
            "[550 | 1305.08] loss=1.76 avg=2.16\n",
            "[560 | 1328.32] loss=1.02 avg=2.13\n",
            "[570 | 1351.55] loss=0.56 avg=2.10\n",
            "[580 | 1374.81] loss=1.11 avg=2.07\n",
            "[590 | 1398.02] loss=1.19 avg=2.05\n",
            "[600 | 1421.23] loss=0.70 avg=2.03\n",
            "======== SAMPLE 1 ========\n",
            " the globalist agenda, to use one of our favorite terms, if you like, the history of the post-racial world, and think Black Americans have a better chance of success at home, would you rather be in a superior position to them than to all Americans? The American story does the same thing, in even greater measure.  In addition to the narratives currently presented, there are also alternative narratives being told about Black Americans.\n",
            "\n",
            "For example, there are white evangelical Christian and antiracist Christians who are openly critical of America, even as their own racial realities are projected to worsen.\n",
            "\n",
            "On the other side, like Black Christians, they are largely indifferent to what is happening in America, even as their own racial realities continue to worsen.\n",
            "\n",
            "These alternative narratives often center on the racial or ethnic profile of people of color, rather than on the racial identities of people of color, a common misperception in Black America. This misperception leads to the assumption that there is something inherently racist about Black Americans, in addition to the misperceptions that racial groups are so interrelated that they are somehow interchangeable.\n",
            "\n",
            "But that doesn’t address the reality that there are racial and socioeconomic categories assigned to people based on their skin color or eye color or hair texture and that those categories are constructed based on how those racial groups look. Therefore, if you want to know the racial wealth of people living in America, you need to look at people in other racial groups. There is no such thing as wealth in too low an index.\n",
            "\n",
            "The same racial groups can look like completely different populations because there is no ideological or cultural bond between those groups.\n",
            "\n",
            "In the case of racial groups, people living in groups and people living in groups may have the same chances at success; this relationship can be complicated by poverty, income, education, race, culture, and even gender.\n",
            "\n",
            "Merely thinking of a racial group as being poor, middle-income or otherwise does not tell you what is wrong with the racial group. Racial groups aren’t a stable racial group, nor can they be cast as such. There are certain racial categories that mirror racial groups, and those racial groups can have very different racial wealth levels.\n",
            "\n",
            "For instance, there are American Indian and Alaska Native people of African descent.\n",
            "\n",
            "There are Alaska Native people of European descent. There are Korean people of African descent. There are Asian people of African descent. There are Latinos and African Americans. There are non-Latino and non-Latino. The racial wealth gap in these racial groups is massive.\n",
            "\n",
            "The gap among Asian Americans is around the racial wealth of Black households in Chicago. Race wealth is so concentrated in Asian Americans that it is hard to see how any racial group would be worth running into on its own, given the wealth gap.\n",
            "\n",
            "What this means, however, is that we can look at racial wealth in an unprecedented way not only in this very moment, but also in 20 or 30 years, if we wish. At an AGI, we could see wealth inequality in ways not seen since the Great Depression. If we wish, we could create wealth by creating an AGI.\n",
            "\n",
            "Then we could start over and try to fill the gap, using the knowledge already available to us, to build an AGI. I suspect we will have an AGI with the power to create great wealth inequality.\n",
            "\n",
            "We may have an AGI with the power to create a wealth disparity so great that we cannot name the individual who is making the disparity. We may have an AGI with the power to create an AGI that can control markets and create extreme wealth inequality.\n",
            "\n",
            "I suspect we will have an AGI capable of valuing people at trillions of dollars in extreme value. In 2031, if we wish, we could build one of the largest computer simulations ever conducted to explore the nature of extreme wealth inequality.\n",
            "\n",
            "We could calculate the extreme wealth inequality for any nation in the industrial capitalist universe, giving us the quintessential test of an AGI.\n",
            "\n",
            "The simulation used in this paper was created assuming an AGI was sufficiently complex to examine the very thing it was designed to probe. This extraordinary development may provide an unprecedented validation of the oft-cited Kardashev-Minsky theory of the unlimited potential of the AGI. It marks the first major advance in scientific understanding of an extraterrestrial intelligence over the last 400 years.\n",
            "\n",
            "This is significant not only because it means we know much more about the mind than was previously thought, and because it means we may be able to build more devices that interact with the earth and beyond which we cannot enter.\n",
            "\n",
            "It also means we may be able to interact with the Earth much more effectively than we were in the past, thanks to intelligent technology. The AGI simulation we chose to use reflected the simulation best practices in the scientific enterprise.\n",
            "\n",
            "But we can improve on it, using our imaginations and creativity, to build a better one\n",
            "\n",
            "[610 | 1454.82] loss=1.21 avg=2.01\n",
            "[620 | 1477.99] loss=1.13 avg=1.99\n",
            "[630 | 1501.16] loss=1.58 avg=1.98\n",
            "[640 | 1524.34] loss=0.94 avg=1.96\n",
            "[650 | 1547.55] loss=1.06 avg=1.94\n",
            "[660 | 1570.77] loss=0.47 avg=1.91\n",
            "[670 | 1593.98] loss=0.50 avg=1.88\n",
            "[680 | 1617.21] loss=1.17 avg=1.87\n",
            "[690 | 1640.46] loss=1.14 avg=1.85\n",
            "[700 | 1663.65] loss=0.74 avg=1.83\n",
            "[710 | 1686.85] loss=0.97 avg=1.81\n",
            "[720 | 1710.04] loss=0.95 avg=1.80\n",
            "[730 | 1733.21] loss=0.36 avg=1.77\n",
            "[740 | 1756.41] loss=0.68 avg=1.75\n",
            "[750 | 1779.59] loss=0.75 avg=1.73\n",
            "[760 | 1802.76] loss=0.50 avg=1.71\n",
            "[770 | 1825.94] loss=0.55 avg=1.68\n",
            "[780 | 1849.13] loss=0.47 avg=1.66\n",
            "[790 | 1872.33] loss=0.67 avg=1.64\n",
            "[800 | 1895.54] loss=0.62 avg=1.62\n",
            "======== SAMPLE 1 ========\n",
            " firm work-flows, focus on low-level, unsupervised learning with high level of confidence.\n",
            "\n",
            "These can be defined asfollowing exactly the path (N = 8),\n",
            "\n",
            "but in the diagram at right, as you can see, these groups can work in tandem (even at very high levels). High-level, bottom-up architectures have been used successfully for many decades. High-level, top-down architectures have been around for many years. This is not an outgrowth of low-level, top-down architectures, this is a result of deep learning as used in narrow-based learning (DLT): when computer memory is limited by its bandwidth, layers are created or filled with networks of layers, which aid in the inference of features by way of solving problem categories, which aid in creating decision trees.\n",
            "\n",
            "In summary, low-level, top-down, high-level architecture emphasize adaptive reuse of data and remove reliance on data warehouses and warehouse drones. The current state of the art in AI is mobility: the Internet of Things enables the manufacturing industry to transport machines more quickly and cheaper than using warehouses.\n",
            "\n",
            "The approach to building out the ultimate IT solution is to make use of the Internet of Things with deep neural networks (DNN), neural network architectures which are full-scale replacements for data warehouses. DNN is a high-performance computing architecture for large-scale image classification.\n",
            "\n",
            "Its main advantage is speed: at its scale image cataloguing of cultural heritage works of art is out of the question. For the moment, however, networks of DNN networks are still the most popular choice.\n",
            "\n",
            "On the other hand, big data can also act as a store of data: social networks of activists, journalists, academics and other users can grow quickly and efficiently. The big challenges with using these tools for image classification are the opacity of the data and the difficulty of decimation using adversarial encryption techniques.\n",
            "\n",
            "The opacity of the data can be reduced in the following way: by lowering the resolution of the stream. This may seem like a big problem, given that the last high-resolution classification of internet users was in 2009, but a dataset of 1 million likes (2000 megapixels) is still only enough to classify 5% of internet users. Lower resolution brings better resolution but at the price of opacity: as the data is reduced, the quality of the output becomes very difficult.\n",
            "\n",
            "High-resolution datasets are also harder to classify because of the large spatial scale of the dataset. The data may be reduced to its entirety (smaller sample size required), or it may be collated and stored as large volumes (1 million or 2 million).\n",
            "\n",
            "Even if the data is reduced, it could still be mined for political speeches and data flows from elections, companies, political groups and governments to political parties and governments, into the scope of mapping. In any case, the data exists, but is being mined for political speech and other data. All of this means it is increasingly difficult to predict the future of a particular political group, make predictions about its policies and operations and vote for them.\n",
            "\n",
            "Because of this, it is not possible to analyze the activity of political groups who publish their activities in the open, and to challenge their activities in public. The internet has come a long way during the past decade, making it possible to communicate with one another and work in the data.\n",
            "\n",
            "But the flow of information is also changing: as the digital divide widens, so does the relational one. Societal reactions to political speech and actions are being produced by social media and printed stories.\n",
            "\n",
            "These technologies enable a new type of information communication, with the world of ideas becoming more responsive to public concerns and legislative processes, as well as the private and public life decisions of groups within society.\n",
            "\n",
            "These tips originated with Cassandra Clare in her January 2013 essay \"What Is News?\" summarizing her work as “Communication becomes part of the fabric of life. And the more people see it, the more they become attracted to it. ” She intended the essay to be a guide to society making discernible social changes, but in her essay she neglects to consider the relational one.\n",
            "\n",
            "She writes, “If people see you as scattered, dispersed, individualistic, and happy in the midst of all that they want, they will be less likely to join you in their circles or to make your acquaintance on their fringes. ”Her essay did not suggest linking people to the internet, but it is here that we must consider the relational one.\n",
            "\n",
            "It is perhaps no surprise, then, that she does not use the term internet. She writes, “The internet is a term for multiple realities: interrelated but interdependent: the individual; the social media user; the print user; and the information the user does 'use or wants to use.\n",
            "\n",
            "”The term “the internet user” is simply “the person using the internet.\n",
            "\n",
            "[810 | 1929.78] loss=0.75 avg=1.61\n",
            "[820 | 1952.98] loss=0.55 avg=1.59\n",
            "[830 | 1976.21] loss=0.41 avg=1.57\n",
            "[840 | 1999.45] loss=0.52 avg=1.55\n",
            "[850 | 2022.67] loss=0.75 avg=1.54\n",
            "[860 | 2045.86] loss=0.63 avg=1.52\n",
            "[870 | 2069.06] loss=0.55 avg=1.50\n",
            "[880 | 2092.25] loss=0.73 avg=1.49\n",
            "[890 | 2115.44] loss=0.34 avg=1.47\n",
            "[900 | 2138.61] loss=0.26 avg=1.45\n",
            "[910 | 2161.77] loss=0.25 avg=1.43\n",
            "[920 | 2184.95] loss=0.48 avg=1.42\n",
            "[930 | 2208.10] loss=0.29 avg=1.40\n",
            "[940 | 2231.23] loss=0.22 avg=1.38\n",
            "[950 | 2254.41] loss=0.31 avg=1.36\n",
            "[960 | 2277.58] loss=0.15 avg=1.34\n",
            "[970 | 2300.74] loss=0.40 avg=1.33\n",
            "[980 | 2323.93] loss=0.37 avg=1.31\n",
            "[990 | 2347.08] loss=0.49 avg=1.30\n",
            "[1000 | 2370.25] loss=0.25 avg=1.28\n",
            "Saving checkpoint/AIR/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe-PboN1wKG6",
        "colab_type": "text"
      },
      "source": [
        "Generate text from our freshly trained GPT-2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyFAcUKqvBG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "bf9d4757-c5f5-4fac-be7b-94aa6fb23fac"
      },
      "source": [
        "def generate_text(prefix, temperature)\n",
        "  tf.reset_default_graph()\n",
        "  sess = gpt2.start_tf_sess()\n",
        "\n",
        "  gpt2.load_gpt2(sess, run_name='AIR')\n",
        "  gen_text = gpt2.generate(sess,model_name='124M',length=50,temperature=temperature,prefix=prefix,nsamples=1,batch_size=1)\n",
        "  return gen_text\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/AIR/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/AIR/model-1000\n",
            "Is the earth flat? Not really. The Earth’s surface is tilted 30 degrees to the center of the Milky Way.\n",
            "\n",
            "The fact that the Milky Way is 30 degrees north or 30 degrees south is a known phenomenon. But the Earth’s surface is\n",
            "====================\n",
            "Is the earth flat? That’s an interesting one. The argument goes that if the earth were lined up exactly one inch from the sun's surface, then the Earth’s gravitational field would be perturbed about the perimeter of the equator.\n",
            "\n",
            "If\n",
            "====================\n",
            "Is the earth flat? The scientists responsible for that prediction say it is not.\n",
            "\n",
            "They add that “it is possible that the planet we know through the power of computers — the one with all the data — might be very different from what we know through the printing\n",
            "====================\n",
            "Is the earth flat? Is the sun not moving? Is the moon not moving? The Sun-God hypothesis is that it is. The argument goes like this: If the Sun-God hypothesis is true, does the Earth-God universe contain more than one living being?\n",
            "====================\n",
            "Is the earth flat? Does it have a mass? Is it circular? The Sun and its gravitational pull can be gauged by his or her apparent location on the face of the planet.\n",
            "\n",
            "The position of the Sun and its apparent location on the planet is called either\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}